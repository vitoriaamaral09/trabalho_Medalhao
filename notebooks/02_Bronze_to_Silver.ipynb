{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1b6e5c-b209-4efe-8275-55faf81daa13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Alteração \n",
    "\n",
    "from pyspark.sql.functions import col, upper, trim, to_timestamp, current_timestamp\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "#alteração apenas para subir no git\n",
    "# Definições de Catálogo e Schema\n",
    "CATALOG_NAME = \"workspace\"\n",
    "SCHEMA_NAME = \"projeto_medalhao_ecommerce\"\n",
    "\n",
    "print(f\"Iniciando transformações da Camada Bronze para Silver no Schema: {SCHEMA_NAME}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Tabela Clientes: Padronização, Limpeza e Remoção de Duplicados\n",
    "# ==============================================================================\n",
    "df_customers_bronze = spark.read.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_customers\")\n",
    "\n",
    "df_customers_silver = (df_customers_bronze\n",
    "    # --- Passo 1: Limpeza/Tratamento usando colunas EXISTENTES\n",
    "\n",
    "    .withColumn(\"name\", trim(col(\"name\"))) # Limpa espaços\n",
    "    \n",
    "    # Data Quality: Remoção de Duplicados (Usando 'customer_id' como ID único neste dataset)\n",
    "    .dropDuplicates([\"customer_id\"])\n",
    "    \n",
    "    # --- Passo 2: Padronização de Nomenclatura ---\n",
    "    .withColumnRenamed(\"customer_id\", \"id_cliente\")\n",
    "    .withColumnRenamed(\"name\", \"nome_cliente\")\n",
    "    .withColumnRenamed(\"email\", \"email_cliente\")\n",
    "    .withColumnRenamed(\"gender\", \"genero\")\n",
    "    .withColumnRenamed(\"signup_date\", \"data_cadastro\")\n",
    "    .withColumnRenamed(\"country\", \"pais\")\n",
    "    \n",
    "    # Adicionar metadado de processamento Silver\n",
    "    .withColumn(\"processamento_silver_ts\", current_timestamp())\n",
    "    \n",
    "    # Remover metadados da Bronze\n",
    "    .drop(\"source_file\", \"ingestion_timestamp\")\n",
    ")\n",
    "\n",
    "# Escrita na Camada Silver (Corrigido para evitar erro de gravação)\n",
    "df_customers_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SCHEMA_NAME}.silver_clientes\")\n",
    "print(\"-> Tabela silver_clientes criada/atualizada com sucesso.\")\n",
    "\n",
    "# Continue com a Seção 2 (Tabela Produtos) e seguintes.\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Tabela Produtos: Conversão de Tipos e Tratamento de Nulos \n",
    "# ==============================================================================\n",
    "df_products_bronze = spark.read.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_products\")\n",
    "\n",
    "df_products_silver = (df_products_bronze\n",
    "    # Padronização de Nomenclatura (USANDO SÓ COLUNAS EXISTENTES: product e category)\n",
    "    .withColumnRenamed(\"product_id\", \"id_produto\")\n",
    "    .withColumnRenamed(\"product\", \"nome_produto\") \n",
    "    .withColumnRenamed(\"category\", \"categoria_produto\") \n",
    "    .withColumnRenamed(\"price\", \"preco\") # Manter essa renomeação para consistência\n",
    "    \n",
    "    # Tratamento de Nulos: Preencher valores nulos (dados ausentes) na categoria\n",
    "    .fillna({\"categoria_produto\": \"SEM_CATEGORIA\"})\n",
    "    \n",
    "    # Removendo colunas que não existem e as antigas de metadados\n",
    "    .drop(\"tamanho_nome_produto\", \"tamanho_descricao_produto\", \"qtd_fotos_produto\") \n",
    "    .drop(\"source_file\", \"ingestion_timestamp\")\n",
    ")\n",
    "\n",
    "# Escrita na Camada Silver (Corrigido para evitar erro de gravação)\n",
    "df_products_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SCHEMA_NAME}.silver_produtos\")\n",
    "print(\"-> Tabela silver_produtos criada/atualizada com sucesso.\")\n",
    "\n",
    "# Continue com a Seção 3 (Tabela Orders) e seguintes.\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Tabela Orders (Pedidos): Tipagem de Datas\n",
    "# ==============================================================================\n",
    "df_orders_bronze = spark.read.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_orders\")\n",
    "\n",
    "date_cols = [\n",
    "    \"order_date\"  # USAR APENAS A COLUNA EXISTENTE\n",
    "]\n",
    "\n",
    "df_orders_silver = df_orders_bronze\n",
    "for col_name in date_cols:\n",
    "    # Conversão de tipo de dado\n",
    "    df_orders_silver = df_orders_silver.withColumn(col_name, to_timestamp(col(col_name)))\n",
    "\n",
    "# Padronização e Filtro\n",
    "df_orders_silver = (df_orders_silver\n",
    "    .withColumnRenamed(\"order_id\", \"id_pedido\")\n",
    "    .withColumnRenamed(\"customer_id\", \"id_cliente\")\n",
    "    .withColumnRenamed(\"order_date\", \"data_pedido\")\n",
    "    \n",
    "    # Filtro: Remover pedidos sem ID (Data Quality)\n",
    "    .filter(col(\"id_pedido\").isNotNull())\n",
    "    .drop(\"source_file\", \"ingestion_timestamp\")\n",
    ")\n",
    "\n",
    "# Escrita na Camada Silver\n",
    "df_orders_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SCHEMA_NAME}.silver_pedidos\")\n",
    "print(\"-> Tabela silver_pedidos criada/atualizada com sucesso.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Tabela Order Items (Itens de Pedido) \n",
    "# ==============================================================================\n",
    "df_items_bronze = spark.read.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_order_items\")\n",
    "\n",
    "df_items_silver = (df_items_bronze\n",
    "    .withColumnRenamed(\"order_id\", \"id_pedido\")\n",
    "    .withColumnRenamed(\"order_item_id\", \"id_item_pedido\")\n",
    "    .withColumnRenamed(\"product_id\", \"id_produto\")\n",
    "    .withColumnRenamed(\"seller_id\", \"id_vendedor\")\n",
    "    \n",
    "    # Coluna REAL é 'unit_price', renomeada para 'preco'\n",
    "    .withColumnRenamed(\"unit_price\", \"preco\") \n",
    "    \n",
    "    # Conversão de tipos de dados numéricos (preco para DoubleType)\n",
    "    .withColumn(\"preco\", col(\"preco\").cast(DoubleType())) \n",
    "    \n",
    "    \n",
    "    # Filtro para garantir integridade básica\n",
    "    .filter(col(\"preco\").isNotNull())\n",
    "    .drop(\"source_file\", \"ingestion_timestamp\")\n",
    ")\n",
    "\n",
    "# Escrita na Camada Silver\n",
    "df_items_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SCHEMA_NAME}.silver_itens_pedido\")\n",
    "print(\"-> Tabela silver_itens_pedido criada/atualizada com sucesso.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Tabela Product Reviews (Avaliações)\n",
    "# ==============================================================================\n",
    "df_reviews_bronze = spark.read.table(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_product_reviews\")\n",
    "\n",
    "df_reviews_silver = (df_reviews_bronze\n",
    "    \n",
    "    # TRATAMENTO 1: Tratar a coluna REAL 'rating' para garantir que seja Integer\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(IntegerType()))\n",
    "    \n",
    "    # Padronização de Nomenclatura\n",
    "    .withColumnRenamed(\"review_id\", \"id_avaliacao\")\n",
    "    .withColumnRenamed(\"order_id\", \"id_pedido\")\n",
    "    .withColumnRenamed(\"rating\", \"score_avaliacao\") # Renomear para o padrão português\n",
    "    \n",
    "    # Opcional: Remova Reviews sem score ou com dados incompletos\n",
    "    .filter(col(\"score_avaliacao\").isNotNull()) # Usar o nome JÁ RENOMEADO, pois a transformação acima já foi resolvida\n",
    "    .drop(\"source_file\", \"ingestion_timestamp\")\n",
    ")\n",
    "\n",
    "# Escrita na Camada Silver\n",
    "df_reviews_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{SCHEMA_NAME}.silver_avaliacoes\")\n",
    "print(\"-> Tabela silver_avaliacoes criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d19043ab-a9b1-4c8b-a882-71a66d231e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Bronze_to_Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
