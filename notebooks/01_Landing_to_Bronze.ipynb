{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06baec78-0f60-469e-a985-93406189829d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb25750a-f9bd-4f78-8f0c-5651ac85f5bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Alteração\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "\n",
    "# 1. Definir o caminho base para a Landing Zone e o novo Schema\n",
    "CATALOG_NAME = \"workspace\" # Seu catálogo principal\n",
    "SCHEMA_NAME = \"projeto_medalhao_ecommerce\" # O novo schema que você criou\n",
    "LANDING_PATH = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/landing_zone/\"\n",
    "\n",
    "# Lista dos 5 arquivos para processar\n",
    "files_to_process = [\"customers.csv\", \"order_items.csv\", \"orders.csv\", \"product_reviews.csv\", \"products.csv\"]\n",
    "\n",
    "for file_name in files_to_process:\n",
    "    table_name = file_name.replace(\".csv\", \"\") # Ex: 'customers'\n",
    "    \n",
    "    # 2. Leitura do CSV (Landing Zone)\n",
    "    df_raw = (spark.read.format(\"csv\")\n",
    "                .option(\"header\", \"true\") \n",
    "                .option(\"inferSchema\", \"true\") # Inferir os tipos de dados\n",
    "                .load(f\"{LANDING_PATH}{file_name}\"))\n",
    "\n",
    "    # 3. Enriquecimento: Adicionar metadados e marcar como 'Bronze'\n",
    "    df_bronze = (df_raw\n",
    "                 .withColumn(\"source_file\", lit(file_name))\n",
    "                 .withColumn(\"ingestion_timestamp\", current_timestamp()))\n",
    "    \n",
    "    # 4. Escrita na Camada Bronze como Tabela Delta\n",
    "    # A tabela será salva como 'projeto_medalhao_ecommerce.bronze_customers'\n",
    "    (df_bronze.write.format(\"delta\")\n",
    "              .mode(\"overwrite\") # Use 'overwrite' para o primeiro teste ou 'append' se for ingestão contínua\n",
    "              .saveAsTable(f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_{table_name}\"))\n",
    "              \n",
    "    print(f\"Tabela {SCHEMA_NAME}.bronze_{table_name} criada com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Landing_to_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
